1.      introduction
1.1     language processors
1.1.1   exercisesfor sections 1.1
1.2     the structure of a compiler
1.2.1   lexical analysis
1.2.2   syntax analysis
1.2.3   semantic analysis
1.2.4   intermediate code generation
1.2.5   code optimization
1.2.6   code generation
1.2.7   symbol-table management
1.2.8   the grouping of phases into passes
1.2.9   compiler-construction tools
1.3     the evolution of programming languages
1.3.1   the move to higher-level languages
1.3.2   impacts on compilers
1.3.3   exercises for section 1.3
1.4     the science of building a compiler
1.4.1   modeling in compiler design and implement
1.2.2   the science of code optimization
1.5     applications of compiler technology
1.5.1   implementation of high-level programming languages
1.5.2   optimizations for computer architectures
1.5.3   design of new computer architectures
1.5.4   program translations
1.5.5   software productivity tools
1.6     programming language basics
1.6.1   the static/dynamic distinction
1.6.2   environments and states
1.6.3   static scope and block structure
1.6.4   explicit access control
1.6.5   dynamic scope
1.6.6   parameter passing mechanisms
1.6.7   aliasing
1.6.8   exercises for section 1.6
1.7     summary of chapter 1
1.8     references for chapter 1
2       a simple syntax-directed translator
2.1     introduction
2.2     syntax definition
2.2.1   definition of grammars
2.2.2   derivations
2.2.3   parse trees
2.2.4   ambiguity
2.2.5   associativity of operators 
2.2.6   precedence of operators
2.2.7   exercises for sections 2.2
2.3     syntax-directed translation
2.3.1   postfix notation
2.3.2   synthesized attributes
2.3.3   simple syntax-directed definitions
2.3.4   tree traversals
2.3.5   translation schemes
2.3.6   exercises for section 2.3
2.4     parsing
2.4.1   top-down parsing
2.4.2   predictive parsing
2.4.3   when to use e-productions
2.4.4   designing a predictive parser
2.4.5   left recursion
2.4.6   exercisesfor section 2.4
2.5     a translator for simple expressions
2.5.1   abstract and concrete syntax
2.5.2   adapting the translation scheme
2.5.3   procedures for the noterminals
2.5.4   simplifying the translator
2.5.5   the complete program
2.6     lexical analysis
2.6.1   removal of white space and comments
2.6.2   reading ahead
2.6.3   constants
2.6.4   recognizing keywords and identifiers
2.6.5   a lexical analyzer
2.6.6   exercises for section 2.6
2.7     symbol tables
2.7.1   symbol table per scope
2.7.2   the use of symbol tables
2.8     intermediate code generation
2.8.1   two kinds of intermediate representations
2.8.2   construction of syntax trees
2.8.3   static checking
2.8.4   three-address code
2.8.5   exercises for section 2.8
2.9     summary of chapter 2
3       lexical analysis
3.1     the role of the lexical analyzer
3.1.1   lexical analysis versus parsing
3.1.2   tokens, patterns, and lexemes
3.1.3   attributes for tokens
3.1.4   lexical errors
3.1.5   exercises for section 3.1
3.2     input buffering
3.2.1   buffer pairs
3.2.2   sentinels
3.3     specification of tokens
3.3.1   strings and languages
3.3.2   operations on language
3.3.3   regular expressions
3.3.4   regular definitions
3.3.5   extensions of regularexpressions
3.3.6   exercises for section 3.3
3.4     recognition of tokens
3.4.1   transition diagrams
3.4.2   recognition of reserved words and identifiers
3.4.3   completion of the running example
3.4.4   architecture of a transition-diagram-based lexical analyzer
3.4.5   exercises for section 3.4
3.5     the lexical-analyzer generator lex
3.5.1   use of lex
3.5.2   structure of lex programs
3.5.3   conflict resolution in lex
3.5.4   the lookahead operator
3.5.5   exercises for section 3.5
3.6     finite automata
3.6.1   nondeterministic finite automata
3.6.2   transition tables
3.6.3   acceptance of input strings by automata
3.6.4   deterministic finite automata
3.6.5   exercises for section 3.6
3.7     from regular expressions to automata
3.7.1   conversion of an NFA to a DFA
3.7.2   simulation of an NFA
3.7.3   efficiency of NFA simulation 
3.7.4   construction of an NFA from a regular expression
3.7.5   efficiency of string-processing algorithms
3.7.6   exercises for section 3.7
3.8     design of a lexical-analyzer generator
3.8.1   the structure of the generated analyzer
3.8.2   pattern matching based on NFA's
3.8.3   DFA's for lexical analyzers
3.8.4   implementing the lookahead operator
3.8.5   exercises for section 3.8
3.9     optimization of DFA-based pattern matchers
3.9.1   important states of an NFA
3.9.2   functions computed from the syntaxtree
3.9.3   computing unliable, firstpos, and lastpos
3.9.4   computing followpos
3.9.5   converting a regular expression directly to a DFA
3.9.6   minimizing the number of states of a DFA
3.9.7   state minimization in lexical analyzers
3.9.8   trading time for space in DFA simulation
3.9.9   exercises for section 3.9
3.10    summary of chapter 3
3.11    references for chapter 3
4       syntax analysis
4.1     introduction
4.1.1   the role of the parser
4.1.2   representative grammars
4.1.3   syntax error handling
4.1.4   error-recovery trategies
4.2     cotnext-free grammars
4.2.1   the formal definition of a context-free grammar
4.2.2   notational conventions
4.2.3   derivations
4.2.4   parse trees and derivations
4.2.5   ambiguity
4.2.6   verifying the language generated by a grammar
4.2.7   context-free grammars versus regular expressions
4.2.8   exercises for section 4.2
4.3     writing a grammar
4.3.1   lexical versus syntactic analysis
4.3.2   eliminating ambiguity
4.3.3   elimination of left recursion
4.3.4   left factoring
4.3.5   non-context-free language constructs
4.3.6   exercises for section 4.3
4.4     top-down parsing
4.4.1   recursive-descent parsing
4.4.2   first and follow
4.4.3   LL(1) grammars
4.4.4   nonrecursive predictive parsing
4.4.5   error recovery in predictive parsing
4.4.6   exercises for section 4.4
4.5     bottom-up parsing
4.5.1   reductions
4.5.2   handle pruning
4.5.3   shift-reduce parsing
4.5.4   conflicts during shift-reduce parsing
4.5.5   exercises for section 4.5
4.6     introduction to LR parsing: simple LR
4.6.1   why LR parsers?
4.6.2   items and the LR(0) automaton
4.6.3   the LR-parsing algorithm
4.6.4   constructing slr-parsing tables
4.6.5   viable prefixes
4.6.6   exercises for section 4.6
4.7     more powerful LR parsers
4.7.1   canonical LR(1) items
4.7.2   constructing LR(1) sets of items
4.7.3   cononical LR(1) parsing tables
4.7.4   constructing LALR parsing tables
4.7.5   efficient construction of LALR parsing tables
4.7.6   compaction of LR parsing tables
4.7.7   exercises for section 4.7
4.8     using ambiguous grammars
4.8.1   precedence and associativity to resolve conflicts
4.8.2   the "dangling-else" ambiguity
4.8.3   error recovery in LR parsing
4.8.4   exercises for section 4.8 
4.9     parser generators
4.9.1   the parser generator YACC
4.9.2   using YACC with ambiguous grammars
4.9.3   creating YACC lexical analyzers with lex
4.9.4   error recovery in YACC
4.9.5   exercises for section 4.9
4.10    summary of chapter 4
4.11    references for chapter 4
5       syntax-directed translation
5.1.1   syntax-directed definitions
5.1.2   evaluating an SDD at the nodes of a parse tree
5.1.3   exercises for section 5.1
5.2     evaluation of orders for SDD's
5.2.1   dependency graphs
5.2.2   ordering the evaluation of attributes
5.2.3   s-attributed definitions
5.2.4   l-attributed definitions
5.2.5   semantic ruleswith controlled side effects
5.2.6   exercises for section 5.2   
5.3     applications of syntax-directed translation
5.3.1   construction of syntax trees
5.3.2   the structure of a type
5.3.3   exercises for section 5.3
5.4     syntax-directed translation schemes
5.4.1   postfix translation schemes
5.4.2   parser-stack implementation of postfix SDT's
5.4.3   SDT's with actions inside productions
5.4.4   eliminating left recursion from SDT's
5.4.5   SDT's for l-attributed definitions
5.4.6   exercises for section 5.4
5.5     implementing l-attributed SDD's
5.5.1   translation during recursive-descent parsing
5.5.2   on-the-fly code generation
5.5.3   l-attributed SDD's and LL parsing
5.5.4   bottom-up parsing of l-attributed SDD's
5.5.5   exercises for section 5.5
5.6     summary of chapter 5
5.7     references for chapter 5
6       intermediate-code generation
6.1     variants of syntax trees
6.1.1   directed acyclic graphs for expression
6.1.2   the vaule-number method for constructing DAG's
6.1.3   exercises for section 6.1
6.2     three-address code
6.2.1   addresses and instructions
6.2.2   quadruples
6.2.3   triples
6.2.4   static single-assignment form
6.2.5   exercises for section 6.2
6.3     types and declarations
6.3.1   type expressions
6.3.2   type equivalence
6.3.3   declarations
6.3.4   storage layout for local names
6.3.5   sequencesof declarations
6.3.6   fields in records and classes
6.3.7   exercises for section 6.3
6.4     translation of expressions
6.4.1   operations within expressions
6.4.2   incremental translation
6.4.3   addressing array elements
6.4.4   translation of array elements
6.4.5   translation of array references
6.4.5   exercises for section 6.4
6.5     type checking
6.5.1   rules for type checking
6.5.2   type conversions
6.5.3   overloading of functions and operators
6.5.4   type inference and polymorphic functions
6.5.5   an algorithm for unification
6.5.6   exercises for section 6.5
6.6     control flow
6.6.1   boolean expressions
6.6.2   short-circuit code
6.6.3   flow-of-control statements
6.6.4   control-flow translation of booleanexpressions
6.6.5   avoiding redundant gotos
6.6.6   boolean values and jumping code
6.6.7   exercises for section 6.6
6.7     backpatching
6.7.1   one-pass code generation using backpatching
6.7.2   backpatching for boolean expressions
6.7.3   flow-of-control statements
6.7.4   break-, continue-, and goto-statements
6.7.5   exercises for section 6.7
6.8     switch-statemetns
6.8.1   translationof switch-statements
6.8.2   syntax-directed translation of switch-statements
6.8.3   exercises for section 6.8
6.9     intermediate code for procedures
6.10    summary of chapter 6
6.11    references for chapter 6
7       run-time environments
7.1     storage organization
7.1.1   static versus dynamic storage allocation
7.2     stack allocation of space
7.2.1   activation trees
7.2.2   activation records
7.2.3   calling sequences
7.2.4   variable-length data on the stack
7.2.5   exercises for section 7.2
7.3     access to nonlocal data on the stack
7.3.1   data access without nested procedures
7.3.2   issuses with nested procedures
7.3.3   a language with nested procedure declarations
7.3.4   nesting depth
7.3.5   access links
7.3.6   manipulating access links
7.3.7   access links for procedure parameters
7.3.8   displays
7.3.9   exercisesfor section 7.3
7.4     heap management
7.4.1   the memory manager
7.4.2   the memory hierachy of a computer
7.4.3   locality in programs
7.4.4   reducing fragmentation
7.4.5   manual deallocation requests
7.4.6   exercises for section 7.4 
7.5     introduction to gargabe collection
7.5.1   design goals for garbage collectors
7.5.2   reachability
7.5.3   reference counting garbage collectors
7.5.4   exercises for section 7.5
7.6     introduction to trace-based collection
7.6.1   a basic mark-and-sweep collector
7.6.2   basic abstraction
7.6.3   optimizing mark-and-sweep
7.6.4   mark-and-compact garbage collectors
7.6.5   copying collectors
7.6.6   comparing costs
7.6.7   exercisesfor section 7.6
7.7     short-pause garbage collection
7.7.1   incremental garbage collection
7.7.2   incremental reachability analysis
7.7.3   partial-collection basicss
7.7.4   generational garbage collection
7.7.5   the train algorithm
7.7.6   exercises for section 7.7
7.8     advanced topics in garbage collection
7.8.1   parallel and concurrent gargabe collection
7.8.2   partial objectrelocation
7.8.3   conservative collection for unsafe languages
7.8.4   weak references
7.8.5   exercises for section 7.8
7.9     summary of chapter 7
7.10    references for chapter 7
